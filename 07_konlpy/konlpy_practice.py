# -*- coding: utf-8 -*-
"""konlpy_practice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1msqKVHPaQ7abrqamYDoReKPwz7VC4qnV
"""

### 나눔 고딕 설치
!apt-get update -qq   # 설치를 업데이트 
!apt-get install fonts-nanum* -qq  # 설치한다. fonts-nanum*

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib as mpl # 기본 설정 만지는 용도
import matplotlib.pyplot as plt # 그래프 그리는 용도
import matplotlib.font_manager as fm # 폰트 관련 용도
import numpy as np

path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf' # 설치된 나눔 글꼴중 원하는 녀석의 전체
font_name = fm.FontProperties(fname=path, size=10).get_name()
print(font_name)
plt.rc('font', family=font_name)

# 우선 fm._rebuild() 를 해주고 # 폰트 매니저 재빌드가 필요하다.
fm._rebuild()

# 데이터 준비
data = np.random.randint(-200, 100, 50).cumsum()

# 그래프를 그려 한글 확인
plt.plot(range(50), data, 'r')
plt.title('시간별 가격 추이')

pip install konlpy

import nltk
from konlpy.tag import Kkma

from wordcloud import WordCloud, STOPWORDS
from PIL import Image
import pandas as pd

text = open("샹치_댓글.csv").read()
text
#text = pd.read_csv("샹치_댓글.csv")
#text[1:100]

from konlpy.tag import Okt
t = Okt()

doc_nouns = t.nouns(text)
print( len(doc_nouns) )

ko = nltk.Text(doc_nouns, name="샹치")
print(type(ko))

type( ko.vocab() ), ko.vocab().most_common(20)

most_fre = ko.vocab().most_common(70)
most_fre

print( len( set( ko.tokens) ) )

plt.figure(figsize=(12,6))
ko.plot(50)
plt.show()

stop_words = ['분노', '영화', '액션', '시리즈', '진짜', 
              '더', '이', '거', '왜', '좀', '뭐', '임', '수', '정도' 
              '돈', '것', '다음', '질주', '그냥', '다른'
              '내', '용', '전' '말', '뭐', '애', '나', '듯', '편', '볼', '범', 
              '중', '로', '눈', '점', '함', '안', '돈', '급',
              '또','욕','도','봄', '씬', '저', '때', '전', '그',
              '만', '말', '내']

new_ko = []
for one_word in ko:
  if one_word not in stop_words:
    new_ko.append(one_word)

new_ko = nltk.Text(new_ko, name='샹치')
plt.figure(figsize=(12,6))
new_ko.plot(50)

plt.figure(figsize=(15,8))
new_ko.dispersion_plot(['스토리','마블','중국영화','재미'])

import numpy as np
from PIL import Image

SC = np.array(Image.open("Robot.png"))

data = new_ko.vocab().most_common(100)

wc = WordCloud(background_color='white', 
               max_words=200,
               mask=SC,   
               contour_width=3, 
               contour_color="steelblue", 
               font_path=path).generate_from_frequencies(dict(data))

plt.figure(figsize=(12,8))
plt.imshow(wc)
plt.axis('off')
plt.show()

